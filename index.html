---
layout: standard
title: Aleksei Petrenko
---
<div>
  <h1 class="title">Hi there, I'm Aleksei Petrenko</h1>

  <img class="photo" src="/assets/montana_2020.jpg" alt="Aleksei photo" />

  <div class="content-col">
    <p class="modest-link"><i>
      <a href="https://www.amazon.com/Artificial-Intelligence-Elaine-Rich/dp/0070522634">Making computers do things at which, at the moment, people are better.
      <span class="modest">(Rich and Knight, 1991)</span></a>
    </i></p>

    <p>
      I am a research scientist at Apple, working on autonomous systems.

      I received my PhD in Computer Science in 2023 from the University of Southern California
      I was a part of Robotics and Embedded Systems Lab and was advised by 
      <a href="https://viterbi.usc.edu/directory/faculty/Sukhatme/Gaurav">prof. Gaurav Sukhatme</a>.
      My research focus is deep reinforcement learning and simulation for robotics and embodied AI.
      <br /><br />
  
      During my PhD I worked at NVIDIA on high-throughput simulation and RL for <a href="dextreme.org">robots</a>, at Intel
      on massively parallel <a href="megaverse.info">3D rendering</a> and <a href="https://www.samplefactory.dev/">high-throughput reinforcement learning</a>.
      
      Before going to academia I spent 8 years in industry, working on software R&D, machine learning, algorithms, 3D graphics, computer vision, and virtual reality.
    </p>

    <h2>Research interests</h2>
    <p>
      I study computationally efficient methods of training agents in simulation using reinforcement learning, as well as problems of sim-to-real transfer.
      Recently I've been working on:
      <ul>
        <li>Highly optimized open-source software for deep reinforcement learning, such as RL algorithms and simulators.</li>
        <li>Advanced training scenarios such as population-based training and self-play.</li>
        <li>Reinforcement learning in robotics: dexterous manipulation and quadrotor swarms.</li>
      </ul>

      In the past I also worked on exploration in RL, memory in embodied agents, and stochastic future prediction.
    
      In the long term, I would like to work on safe AI for scientific discovery, one that would allow us to tackle fundamental scientific challenges
      like human longevity, fusion energy, and minimization of various X-risks. 
    </p>

    <h2>Recent publications:</h2>
    <small>
    <b>2022:</b>
    <ul><li>
      <u>A Petrenko</u>, A Allshire, G State, A Handa, V Makoviychuk.
      <b>DexPBT: Scaling up Dexterous Manipulation for Hand-Arm Systems with Population Based Training.</b>
      <i>Submitted to RSS 2023.</i><br />
      <!-- <a href="https://arxiv.org/abs/2107.08170">[Paper]</a>
      <a href="https://github.com/alex-petrenko/megaverse">[Code]</a>
      <a href="https://www.megaverse.info/">[Website]</a><br /> -->
      Large-scale reinforcement learning for high-DoF hand-arm systems.

      <!-- <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
        <img class="images" src="/assets/megaverse_1.gif" width="320" alt="Megaverse gif" />
        <img class="images" src="/assets/megaverse_2.gif" width="320" alt="Megaverse gif" />
      </div> -->

    </li>
    <li>
      A Handa*, A Allshire*, V Makoviychuk*, <u>A Petrenko*</u>, R Singh*, J Liu*, D Makoviichuk, K Van Wyk, A Zhurkevich, B Sundaralingam, Y Narang, J Lafleche, D Fox, G State.
      <b>DeXtreme: Transfer of Agile In-hand Manipulation from Simulation to Reality.</b>
      <i>In ICRA 2023.</i><br />
      <a href="https://arxiv.org/pdf/2210.13702.pdf">[Paper]</a>
      <a href="https://dextreme.org/">[Website]</a><br/>
      Learning dexterous in-hand manipulation in vectorized simulation and deploying policies on the real robot.<br />

      <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">  
        <video src="https://dextreme.org/static/images/teaser.mp4" controls="controls" muted="muted" autoplay="true" class="images" style="max-width:320px;" />
      </div>
    </li>
    </ul>
    <b>2021:</b>
    <ul><li>
      <u>A Petrenko</u>, E Wijmans, B Shacklett, V Koltun.
      <b>Megaverse: Simulating Embodied Agents at One Million Experiences per Second.</b>
      <i>In ICML2021.</i><br />
      <a href="https://arxiv.org/abs/2107.08170">[Paper]</a>
      <a href="https://github.com/alex-petrenko/megaverse">[Code]</a>
      <a href="https://www.megaverse.info/">[Website]</a><br />
      The fastest (at the time of release) embodied simulator for AI research. 1,000,000+ FPS of immersive experience on a single machine.

      <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
        <img class="images" src="/assets/megaverse_1.gif" width="320" alt="Megaverse gif" />
        <img class="images" src="/assets/megaverse_2.gif" width="320" alt="Megaverse gif" />
      </div>

    </li>
    <li>
      S Batra*, Z Huang*, <u>A Petrenko*</u>, T Kumar, A Molchanov, G Sukhatme.
      <b>Decentralized Control of Quadrotor Swarms with End-to-end Deep Reinforcement Learning.</b>
      <i>In CORL2021.</i><br />
      <a href="https://arxiv.org/abs/2109.07735">[Paper]</a>
      <a href="https://github.com/Zhehui-Huang/quad-swarm-rl/">[Code]</a>
      <a href="https://sites.google.com/view/swarm-rl">[Website]</a>

      End-to-end learning of neural policies for quadrotor swarms with sim-to-real transfer.

      <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
        <img class="images" src="/assets/quads_1.gif" width="320" alt="Quads gif" />
        <img class="images" src="/assets/quads_2.gif" width="320" alt="Quads gif" />
      </div>

    </li>
    <li>
      S Hegde, A Kanervisto, <u>A Petrenko</u>.
      <b>Agents that Listen: High-Throughput Reinforcement Learning with Multiple Sensory Systems.</b>
      <i>In IEEE Conference on Games, 2021.</i><br />
      <a href="https://arxiv.org/abs/2107.02195">[Paper]</a>
      <a href="https://github.com/hegde95/Agents_that_Listen">[Code]</a>
      <a href="https://sites.google.com/view/sound-rl">[Website]</a>
    </li>
    <li>
      B Shacklett, E Wijmans, <u>A Petrenko</u>, M Savva, D Batra, V Koltun, K Fatahalian.
      <b>Large Batch Simulation for Deep Reinforcement Learning.</b>
      <i>In ICLR2021.</i><br>
      <a href="https://arxiv.org/abs/2103.07013">[Paper]</a>
      <a href="https://github.com/shacklettbp/bps-nav">[Code]</a>
    </li>
    </ul>
    <b>2020:</b>
    <ul><li>
      <u>A Petrenko</u>, Z Huang, T Kumar, G Sukhatme, V Koltun.
      <b>Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning.</b> 
      <i>In ICML2020.</i><br />
      <a href="https://arxiv.org/abs/2006.11751">[Paper]</a>
      <a href="https://github.com/alex-petrenko/sample-factory">[Code]</a>
      <a href="https://sites.google.com/view/sample-factory/home">[Website]</a>
      <a href="https://youtu.be/lLG17LKKSZc">[Talk]</a><br />

      <a href="https://venturebeat.com/2020/06/24/intels-sample-factory-speeds-up-reinforcement-learning-training-on-a-single-pc/">[Press #1]</a>
      <a href="https://analyticsindiamag.com/intels-new-ai-system-can-optimise-reinforcement-learning-training-on-a-single-system/">[Press #2]</a>
      <a href="https://news.ycombinator.com/item?id=23875367">[Press #3]</a>
      <a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/powerful-ai-can-now-be-trained-on-a-single-computer">[Press #4]</a>
      <br>
      Reinforcement learning framework with the highest single-machine training throughput at the time of publication, ~10x faster
      than traditional synchronous RL implementations. SOTA results in challenging VizDoom and DMLab environments.

      <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
        <img class="images" src="/assets/sf_battle.gif" width="320" alt="VizDoom maze sparse" />
        <img class="images" src="/assets/sf_duel.gif" width="320" alt="VizDoom maze" />
      </div>
    </li></ul>
    </small>

    <h2>Selected open-source projects:</h2>
    <ul>
      <li>
      <i><a href="https://github.com/alex-petrenko/sample-factory">https://github.com/alex-petrenko/sample-factory</a></i><br />
      High-throughput asynchronous reinforcement learning framework.
      </li>
      <li>
      <i><a href="https://github.com/alex-petrenko/megaverse">https://github.com/alex-petrenko/megaverse</a></i><br />
      Embodied simulation for RL research at 1,000,000 FPS.
      </li>
      <li>
      <i><a href="https://github.com/alex-petrenko/faster-fifo">https://github.com/alex-petrenko/faster-fifo</a></i><br />
      A faster alternative to built-in Python multiprocessing.Queue.
      </li>
      <li>
      <i><a href="https://github.com/alex-petrenko/signal-slot">https://github.com/alex-petrenko/signal-slot</a></i><br />
      Python implementation of Qt-like signal & slot asynchronous programming paradigm with focus on multiprocessing applications.
      </li>
      <li>
        <i><a href="https://github.com/alex-petrenko/tf-reinforce">github.com/alex-petrenko/tf-reinforce</a></i><br />
        Tensorflow implementation of classic
        policy gradient algorithm for continuous control tasks
      </li>
      <li>
          <i><a href="https://github.com/alex-petrenko/snake-rl">github.com/alex-petrenko/snake-rl</a></i><br />
          RL algorithms for classic Snake game
          (<a href="https://youtu.be/bh_5aIqVTUY">youtube</a>)
        </li>
      <li>
        <i><a href="https://github.com/alex-petrenko/udacity-deep-learning/blob/master/hyperopt.py">hyperopt.py</a></i><br />
        Evolutionary algorithm for hyperparameter optimization in deep learning (it works!)
      </li>
      <li>
        <i><a href="https://github.com/alex-petrenko/udacity-linear-algebra-cpp">github.com/alex-petrenko/udacity-linear-algebra-cpp</a></i><br />
        Small linear algebra library in C++11/14 with templates, SFINAE, etc.
      </li>
    </ul>


    <h2>Other research projects:</h2>

    <h3>Curiosity-driven Exploration in RL (2018)</h3>
    <i><a href="https://github.com/alex-petrenko/curious-rl">github.com/alex-petrenko/curious-rl</a></i><br />
    Tensorflow implementation of the method
    <a href="https://pathak22.github.io/noreward-rl/resources/icml17.pdf">"Curiosity-driven Exploration by Self-supervised Prediction"</a>
    by Pathak et al. for hard exploration tasks in 3D pixel-based environment.

    <div style="display:block;margin-top: 15px; margin-bottom: 30px" align="center">
      <img class="images" src="/assets/doom_maze.gif" alt="VizDoom maze" />
      <img class="images" src="/assets/doom_very_sparse.gif" alt="VizDoom maze sparse" />
    </div>
    
    <br />
    <h3>RL agents for a game "MicroTbs" (2017)</h3>
    <i><a href="https://github.com/alex-petrenko/rl-experiments">github.com/alex-petrenko/rl-experiments</a></i><br />
    An OpenAI Gym-compatible 2D environment and some RL algorithms trained in it: Double DQN, A2C, etc.
    Inspired by an old game <a href="/assets/homm3.jpg">Heroes of Might and Magic III</a>, which is quite challenging for contemporary AI.
    I designed this environment to resemble some of the features of the original game: scouting, different terrain, picking up resources, etc.
    A sample video (more in the repository):
    <iframe
      class="fancy-border youtube-iframe"
      width="560" height="315"
      src="https://www.youtube.com/embed/CP94lSM0zGM" frameborder="0" allowfullscreen>
    </iframe>

    <br />
    <h3>Capturing volumetric video (2017)</h3>
    <p>
    <i><a href="https://github.com/alex-petrenko/4dvideo">github.com/alex-petrenko/4dvideo</a></i><br />
    "4D video" grabber and player for Intel RealSense and Google Tango.
    The player is based on modified Guibas-Stolfi triangulation algorithm and can generate 3D mesh in realtime (300fps on PC, 100fps on Android).
    With this software I captured <a href="https://skfb.ly/6s77X">a lot</a> of cool 4D clips:
    </p>
    <div class="sf-div">
    <div class="sketchfab-embed-wrapper"><iframe class="sf-iframe-single" src="https://sketchfab.com/models/fa1652c6619b4d39a4b754f225123518/embed?preload=1" frameborder="0" allowvr allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/models/fa1652c6619b4d39a4b754f225123518?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">4D video (R200 #01, with texture)</a>
        by <a href="https://sketchfab.com/apetrenko1991?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">apetrenko1991</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
    </div>
    </div>

    <p>I also made some algorithm <a href="https://www.youtube.com/playlist?list=PLpDtE3hf0mXg1FOivZkrsHTdirfHuLPW1">visualizations</a> for fun, check 'em out!

    <br /><br />
    <h2>Industry and applied research:</h2>
    <h3>itSeez3D: Avatar SDK (2016-2018)</h3>
    <p>At <a href="https://itseez3d.com/">itSeez3D</a> I worked on a very interesting project called
    <a href="https://avatarsdk.com">AvatarSDK</a>.
    AvatarSDK is a deep-learning based pipeline for human digitization.
    Check out some of my digital copies automatically generated by our system (<a href=/bonus_avatars>and a bonus</a>):</p>
    <div class="sf-div">
    <div class="sketchfab-embed-wrapper-left"><iframe class="sf-iframe" src="https://sketchfab.com/models/2714d2764b5f427ba70ed2946a10cc60/embed?preload=1" frameborder="0" allowvr allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/models/2714d2764b5f427ba70ed2946a10cc60?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Avatar from GDC 2017</a>
        by <a href="https://sketchfab.com/itseez3d?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">itSeez3D</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
    </div>
    <div class="sketchfab-embed-wrapper-right"><iframe class="sf-iframe" src="https://sketchfab.com/models/e540bf23441d4180a39dbbf9abb6579c/embed?preload=1" frameborder="0" allowvr allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/models/e540bf23441d4180a39dbbf9abb6579c?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Alex | Avatar SDK</a>
        by <a href="https://sketchfab.com/itseez3d?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">itSeez3D</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
    </div>
    </div>
    <h3>itSeez3D: Mobile 3D scanner (2013-2017)</h3>
    <p>With itSeez, and later itSeez3D I participated in the development of the <a href="https://itseez3d.com">3D scanning software</a> for various structured light sensors.
    Our results are close to those of professional 3D scanners, for 10-100x less money!
    Hey, this page needs more Sketchfab embeds:</p>

    <div class="sf-div">
    <div class="sketchfab-embed-wrapper"><iframe class="sf-iframe-single" src="https://sketchfab.com/models/1bbfddd77b1647e183ae7f9d9ea32111/embed?autospin=0.2&amp;preload=1" frameborder="0" allowvr allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe>
    <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/models/1bbfddd77b1647e183ae7f9d9ea32111?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Cow</a>
        by <a href="https://sketchfab.com/itseez3d?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">itSeez3D</a>
        on <a href="https://sketchfab.com?utm_medium=embed&utm_source=website&utm_campain=share-popup" target="_blank" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
    </p>
    </div>
    </div>
    <br/>
    <p>Let's <a href="mailto:apetrenko1991@gmail.com">get in touch!</a>
  </div>
</div>
